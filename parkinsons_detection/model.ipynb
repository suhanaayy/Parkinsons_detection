{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "tvXZ75goYXiw",
        "outputId": "709db836-de8a-4e24-9662-2c50bee17507"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-98706db8-0246-4b81-8e89-04fb312bc8d7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-98706db8-0246-4b81-8e89-04fb312bc8d7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset.zip to dataset.zip\n"
          ]
        }
      ],
      "source": [
        "# Upload\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip\n",
        "import zipfile\n",
        "zip_path = 'dataset.zip'  # Replace with your uploaded zip name\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('new folder')\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Patient files:\", os.listdir('new folder/new folder/patients'))\n",
        "print(\"Non-patient files:\", os.listdir('new folder/new folder/non_patients'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnqcjcEmY_Ez",
        "outputId": "650adad4-079c-40f9-c772-08b9454f50b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient files: ['best_segment_cleaned (16).csv', 'best_segment_cleaned (20).csv', 'best_segment_cleaned (18).csv', 'best_segment_cleaned (19).csv']\n",
            "Non-patient files: ['D_First10k.csv', 'processed_eye_data (15).csv', 'processed_eye_data (14).csv', 'D_remaining.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create new folder\n",
        "os.makedirs('new_folder', exist_ok=True)\n",
        "\n",
        "# Move and rename patient files\n",
        "patient_path = 'new folder/new folder/patients'\n",
        "for i, file in enumerate(os.listdir(patient_path)):\n",
        "    if file.endswith('.csv'):\n",
        "        new_name = f'P_{i}.csv'  # P_ prefix for patients\n",
        "        shutil.move(os.path.join(patient_path, file), os.path.join('new_folder', new_name))\n",
        "\n",
        "# Move and rename non-patient files\n",
        "non_patient_path = 'new folder/new folder/non_patients'\n",
        "for i, file in enumerate(os.listdir(non_patient_path)):\n",
        "    if file.endswith('.csv'):\n",
        "        new_name = f'N_{i}.csv'  # N_ prefix for non-patients\n",
        "        shutil.move(os.path.join(non_patient_path, file), os.path.join('new_folder', new_name))\n",
        "\n",
        "print(\"All files moved and renamed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2EEsPSbai8Y",
        "outputId": "88c7fc87-e3f6-403e-a3b6-d0e112cf6058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files moved and renamed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = 'new_folder'\n",
        "\n",
        "# Initialize\n",
        "patient_cols = None\n",
        "non_patient_cols = None\n",
        "\n",
        "# Loop through files and find one patient and one non-patient file\n",
        "for file in os.listdir(folder_path):\n",
        "    if file.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        df = pd.read_csv(file_path, nrows=1)  # only read first row for speed\n",
        "\n",
        "        if file.startswith('P_') and patient_cols is None:\n",
        "            patient_cols = df.columns.tolist()\n",
        "            print(\"Patient File Columns:\")\n",
        "            print(patient_cols)\n",
        "\n",
        "        elif file.startswith('N_') and non_patient_cols is None:\n",
        "            non_patient_cols = df.columns.tolist()\n",
        "            print(\"\\nNon-Patient File Columns:\")\n",
        "            print(non_patient_cols)\n",
        "\n",
        "        # Break if both found\n",
        "        if patient_cols and non_patient_cols:\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erfv6KOxvmIR",
        "outputId": "3cf45058-d747-4d01-9136-e1c24221cc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient File Columns:\n",
            "['timestamp', 'RecordingTime [ms]', 'gaze_x', 'gaze_y', 'blink', 'saccade_velocity', 'fixation', 'pupil_size', 'left_pupil_x', 'left_pupil_y', 'left_pupil_diameter', 'right_pupil_x', 'right_pupil_y', 'right_pupil_diameter', 'PoR_binocular_x', 'PoR_binocular_y', 'Point of Regard Right X', 'Point of Regard Right Y', 'Point of Regard Left X', 'Point of Regard Left Y', 'Category Binocular', 'Index Binocular', 'group_change', 'is_short_blink', 'is_long_blink', 'is_uncategorized']\n",
            "\n",
            "Non-Patient File Columns:\n",
            "['timestamp', 'gaze_x', 'gaze_y', 'eye_aspect_ratio', 'blink', 'saccade_velocity', 'fixation', 'pupil_size', 'left_pupil_x', 'left_pupil_y', 'left_pupil_diameter', 'right_pupil_x', 'right_pupil_y', 'right_pupil_diameter', 'por_binocular_x', 'por_binocular_y', 'point_of_regard_right_x', 'point_of_regard_right_y', 'point_of_regard_left_x', 'point_of_regard_left_y', 'category_binocular', 'index_binocular', 'gx_med', 'gy_med', 'sv_grp', 'RecordingTime [ms]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def extract_features(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Normalize column names to lowercase\n",
        "    df.columns = [col.lower() for col in df.columns]\n",
        "\n",
        "    # Fix naming differences\n",
        "    cat_col = 'category_binocular' if 'category_binocular' in df.columns else 'category binocular'\n",
        "\n",
        "    # Basic derived features\n",
        "    total_rows = len(df)\n",
        "    blink_ratio = (df[cat_col] == 'Blink').sum() / total_rows\n",
        "    saccade_ratio = (df[cat_col] == 'Saccade').sum() / total_rows\n",
        "    visual_ratio = ((df[cat_col] == 'Visual Intake') | (df[cat_col] == 'Fixation')).sum() / total_rows\n",
        "\n",
        "    mean_saccade_velocity = df['saccade_velocity'].mean()\n",
        "    mean_pupil_size = df['pupil_size'].mean()\n",
        "    std_pupil_size = df['pupil_size'].std()\n",
        "\n",
        "    # Optional blink features\n",
        "    short_blink_count = df['is_short_blink'].sum() if 'is_short_blink' in df.columns else 0\n",
        "    long_blink_count = df['is_long_blink'].sum() if 'is_long_blink' in df.columns else 0\n",
        "\n",
        "    return {\n",
        "        'blink_ratio': blink_ratio,\n",
        "        'saccade_ratio': saccade_ratio,\n",
        "        'visual_ratio': visual_ratio,\n",
        "        'mean_saccade_velocity': mean_saccade_velocity,\n",
        "        'mean_pupil_size': mean_pupil_size,\n",
        "        'std_pupil_size': std_pupil_size,\n",
        "        'short_blink_count': short_blink_count,\n",
        "        'long_blink_count': long_blink_count\n",
        "    }\n"
      ],
      "metadata": {
        "id": "kGPx3_2DwIoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "folder_path = 'new_folder'\n",
        "\n",
        "for file in os.listdir(folder_path):\n",
        "    if file.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        features = extract_features(file_path)\n",
        "        label = 1 if file.startswith('P_') else 0\n",
        "        data.append(features)\n",
        "        labels.append(label)\n",
        "\n",
        "X = pd.DataFrame(data)\n",
        "y = pd.Series(labels)\n"
      ],
      "metadata": {
        "id": "bQuuIsD8wMId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPGDzMpDwSVd",
        "outputId": "66c9eba1-859a-49c1-e29d-c7a1e18ca11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for train_idx, test_idx in loo.split(X):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    y_true.append(y_test.values[0])\n",
        "    y_pred.append(pred[0])\n",
        "\n",
        "# Evaluate\n",
        "print(\"LOOCV Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOb57pq2wovU",
        "outputId": "89ddfd99-4324-4638-cac2-0d9ac5527673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOOCV Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for train_idx, test_idx in loo.split(X):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    model = KNeighborsClassifier(n_neighbors=1)  # You can also try k=3 later\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    y_true.append(y_test.values[0])\n",
        "    y_pred.append(pred[0])\n",
        "\n",
        "# Evaluate\n",
        "print(\"LOOCV Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2xr70ZRw4Ou",
        "outputId": "2088c04e-3f48-4978-aea7-5ca75dcff6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOOCV Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_sequence(file_path, max_len=300):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Normalize column names\n",
        "    df.columns = [c.lower().strip() for c in df.columns]\n",
        "\n",
        "    # Use category_binocular to define blink\n",
        "    cat_col = 'category_binocular' if 'category_binocular' in df.columns else 'category binocular'\n",
        "    df['blink_bin'] = df[cat_col].apply(lambda x: 1 if str(x).strip().lower() == 'blink' else 0)\n",
        "\n",
        "    # Select features (you can add more like saccade_velocity, pupil_size, etc.)\n",
        "    features = ['gaze_x', 'gaze_y', 'saccade_velocity', 'pupil_size', 'blink_bin']\n",
        "    df = df[[f for f in features if f in df.columns]].copy()\n",
        "\n",
        "    # Fill missing\n",
        "    df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "    # Pad or truncate\n",
        "    if len(df) > max_len:\n",
        "        df = df.iloc[:max_len]\n",
        "    else:\n",
        "        pad_len = max_len - len(df)\n",
        "        df = pd.concat([df, pd.DataFrame(np.zeros((pad_len, df.shape[1])), columns=df.columns)], axis=0)\n",
        "\n",
        "    return df.values\n"
      ],
      "metadata": {
        "id": "v9-NZbg7xZcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for file in os.listdir('new_folder'):\n",
        "    if file.endswith('.csv'):\n",
        "        file_path = os.path.join('new_folder', file)\n",
        "        label = 1 if file.startswith('P_') else 0\n",
        "        X.append(load_sequence(file_path))\n",
        "        y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0ieghInxdcl",
        "outputId": "bbb8021e-08ed-4f93-c837-5aa382a66b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-12-3077341575.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "5qC3B6ngyEOg",
        "outputId": "57b2c1ea-f650-4686-ca9a-6ddd6f710050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m17,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,033\u001b[0m (78.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,033</span> (78.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,033\u001b[0m (78.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,033</span> (78.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=30, batch_size=1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fNVetnUyOj4",
        "outputId": "b12e9da1-ad15-4751-9b8a-35acfb4b00e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6964 - loss: 0.6056\n",
            "Epoch 2/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9573 - loss: 0.2714\n",
            "Epoch 3/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9053 - loss: 0.2587\n",
            "Epoch 4/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.1447\n",
            "Epoch 5/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0868\n",
            "Epoch 6/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0702\n",
            "Epoch 7/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0533\n",
            "Epoch 8/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0433\n",
            "Epoch 9/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0388\n",
            "Epoch 10/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0383\n",
            "Epoch 11/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0232\n",
            "Epoch 12/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0154\n",
            "Epoch 13/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0359\n",
            "Epoch 14/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0119\n",
            "Epoch 15/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0095\n",
            "Epoch 16/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0248\n",
            "Epoch 17/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0252\n",
            "Epoch 18/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0076\n",
            "Epoch 19/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0170\n",
            "Epoch 20/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0061\n",
            "Epoch 21/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0105\n",
            "Epoch 22/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0051\n",
            "Epoch 23/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 24/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 25/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0099\n",
            "Epoch 26/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0072\n",
            "Epoch 27/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0276\n",
            "Epoch 28/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 29/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 30/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0058\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f421113da10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = tf.keras.models.clone_model(model)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=62, batch_size=1, verbose=0)\n",
        "\n",
        "    pred = (model.predict(X_test)[0][0] > 0.5).astype(int)\n",
        "\n",
        "    y_true.append(y_test[0])\n",
        "    y_pred.append(pred)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdZBBflKygcy",
        "outputId": "efdbbea6-4132-453e-babc-26986441cd6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79b937d372e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79b9404800e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "vzy50C19zJ1X",
        "outputId": "aea0298b-59a1-4bcc-bfe5-a5460eec860f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2dbf3e39-121b-4465-b0cd-24b268f9ba4b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2dbf3e39-121b-4465-b0cd-24b268f9ba4b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving processed_eye_data (22).csv to processed_eye_data (22) (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def preprocess_new_file(file_path, max_len=300):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.columns = [c.lower().strip() for c in df.columns]\n",
        "\n",
        "    cat_col = 'category_binocular' if 'category_binocular' in df.columns else 'category binocular'\n",
        "    df['blink_bin'] = df[cat_col].apply(lambda x: 1 if str(x).strip().lower() == 'blink' else 0)\n",
        "\n",
        "    features = ['gaze_x', 'gaze_y', 'saccade_velocity', 'pupil_size', 'blink_bin']\n",
        "    df = df[[f for f in features if f in df.columns]].copy()\n",
        "\n",
        "    df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "    if len(df) > max_len:\n",
        "        df = df.iloc[:max_len]\n",
        "    else:\n",
        "        pad_len = max_len - len(df)\n",
        "        df = pd.concat([df, pd.DataFrame(np.zeros((pad_len, df.shape[1])), columns=df.columns)], axis=0)\n",
        "\n",
        "    return df.values.reshape(1, max_len, len(df.columns))  # reshape for LSTM: (1, timesteps, features)\n",
        "\n"
      ],
      "metadata": {
        "id": "7xvi1AEiy_ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: load your new test file\n",
        "new_file_path = 'processed_eye_data (22).csv'  # Change this to your file name\n",
        "\n",
        "X_new = preprocess_new_file(new_file_path)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(X_new)[0][0]  # Output is probability\n",
        "\n",
        "# Threshold at 0.5\n",
        "if prediction > 0.5:\n",
        "    print(\"🧠 Predicted: Parkinson’s Patient (Prob =\", round(prediction, 3), \")\")\n",
        "else:\n",
        "    print(\"✅ Predicted: Non-Parkinson’s (Prob =\", round(prediction, 3), \")\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VXDLwap0MHr",
        "outputId": "d66f4a54-1b39-4cb2-af17-4f08b7784522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "✅ Predicted: Non-Parkinson’s (Prob = 0.001 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-17-303486566.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_windowed_sequences(file_path, label, window_size=500, step=500):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.columns = [c.lower().strip() for c in df.columns]\n",
        "\n",
        "    cat_col = 'category_binocular' if 'category_binocular' in df.columns else 'category binocular'\n",
        "    df['blink_bin'] = df[cat_col].apply(lambda x: 1 if str(x).strip().lower() == 'blink' else 0)\n",
        "\n",
        "    features = ['gaze_x', 'gaze_y', 'saccade_velocity', 'pupil_size', 'blink_bin']\n",
        "    df = df[[f for f in features if f in df.columns]].copy()\n",
        "    df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for start in range(0, len(df) - window_size + 1, step):\n",
        "        window = df.iloc[start:start + window_size].values\n",
        "        sequences.append(window)\n",
        "        labels.append(label)\n",
        "\n",
        "    return sequences, labels\n"
      ],
      "metadata": {
        "id": "fi63bS-I2gzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "folder = 'new_folder'\n",
        "\n",
        "for file in os.listdir(folder):\n",
        "    if file.endswith('.csv'):\n",
        "        label = 1 if file.startswith('P_') else 0\n",
        "        file_path = os.path.join(folder, file)\n",
        "        windows, labels = load_windowed_sequences(file_path, label)\n",
        "        X.extend(windows)\n",
        "        y.extend(labels)\n",
        "\n",
        "X = np.array(X)  # Shape: (samples, timesteps, features)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp_zEjrd2kd4",
        "outputId": "3ba8a1e4-646a-4be3-8914-8f3a707028e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=15, batch_size=8, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYzKRrCs2pOt",
        "outputId": "12a4a785-e110-42f0-8728-62b1082dd84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 341ms/step - accuracy: 0.6528 - loss: 0.6524 - val_accuracy: 0.5000 - val_loss: 0.6106\n",
            "Epoch 2/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5556 - loss: 0.6275 - val_accuracy: 1.0000 - val_loss: 0.5201\n",
            "Epoch 3/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.5250 - val_accuracy: 1.0000 - val_loss: 0.4675\n",
            "Epoch 4/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.5340 - val_accuracy: 1.0000 - val_loss: 0.4523\n",
            "Epoch 5/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.4290 - val_accuracy: 1.0000 - val_loss: 0.4062\n",
            "Epoch 6/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.3423 - val_accuracy: 1.0000 - val_loss: 0.3592\n",
            "Epoch 7/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.3690 - val_accuracy: 1.0000 - val_loss: 0.3168\n",
            "Epoch 8/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.2649 - val_accuracy: 1.0000 - val_loss: 0.2824\n",
            "Epoch 9/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.2621 - val_accuracy: 1.0000 - val_loss: 0.2503\n",
            "Epoch 10/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.2046 - val_accuracy: 1.0000 - val_loss: 0.2158\n",
            "Epoch 11/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.1750 - val_accuracy: 1.0000 - val_loss: 0.1831\n",
            "Epoch 12/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.1490 - val_accuracy: 1.0000 - val_loss: 0.1504\n",
            "Epoch 13/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.1350 - val_accuracy: 1.0000 - val_loss: 0.1348\n",
            "Epoch 14/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.1055 - val_accuracy: 1.0000 - val_loss: 0.1256\n",
            "Epoch 15/15\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0945 - val_accuracy: 1.0000 - val_loss: 0.1198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f418d2c87d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new, _ = load_windowed_sequences('best_segment_cleaned (23).csv', label=0)\n",
        "X_new = np.array(X_new)\n",
        "preds = model.predict(X_new)\n",
        "mean_pred = preds.mean()\n",
        "\n",
        "print(\"Mean prediction probability across windows:\", round(mean_pred, 4))\n",
        "\n",
        "if mean_pred > 0.6:\n",
        "    print(\"🧠 Parkinson’s\")\n",
        "elif mean_pred < 0.4:\n",
        "    print(\"✅ Non-Parkinson’s\")\n",
        "else:\n",
        "    print(\"🤔 Uncertain\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1zHxNrT2zMj",
        "outputId": "27a5e152-c844-49e8-ad30-8fa598e540b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Mean prediction probability across windows: 0.9999\n",
            "🧠 Parkinson’s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-1324567508.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Clean columns\n",
        "    df.columns = df.columns.str.replace('\\xa0', ' ', regex=True)\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Debug: Check if key columns exist\n",
        "    required_columns = ['recordingtime [ms]', 'blink', 'fixation', 'saccade_velocity', 'por_binocular_x', 'por_binocular_y']\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Column '{col}' not found in {file_path}\")\n",
        "\n",
        "    # Calculate time differences (in seconds)\n",
        "    time_diff_series = df['recordingtime [ms]'].diff() / 1000.0  # ms to seconds\n",
        "    time_diff_series.iloc[0] = 0  # First row has no previous row\n",
        "\n",
        "    # Remove invalid or zero time differences to avoid division errors\n",
        "    time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
        "\n",
        "    total_time_s = time_diff_series.sum()\n",
        "\n",
        "    # Blink rate (blinks per second)\n",
        "    total_blinks = df['blink'].sum()\n",
        "    blink_rate = total_blinks / total_time_s if total_time_s > 0 else 0\n",
        "\n",
        "    # Calculate average blink duration\n",
        "    blink_durations = []\n",
        "    current_blink_duration = 0\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if df['blink'].iloc[i] == 1:\n",
        "            current_blink_duration += time_diff_series.iloc[i]\n",
        "        elif current_blink_duration > 0:\n",
        "            blink_durations.append(current_blink_duration)\n",
        "            current_blink_duration = 0\n",
        "\n",
        "    if current_blink_duration > 0:\n",
        "        blink_durations.append(current_blink_duration)\n",
        "\n",
        "    avg_blink_duration = np.mean(blink_durations) if blink_durations else 0\n",
        "\n",
        "    # Fixation stability\n",
        "    fixation_percentage = df['fixation'].sum() / len(df) if len(df) > 0 else 0\n",
        "\n",
        "    # Saccade statistics\n",
        "    saccade_mean = df['saccade_velocity'].mean()\n",
        "    saccade_max = df['saccade_velocity'].max()\n",
        "\n",
        "    # Saccade frequency\n",
        "    saccade_threshold = 30  # Adjustable threshold\n",
        "    saccade_count = (df['saccade_velocity'] > saccade_threshold).sum()\n",
        "    saccade_frequency = saccade_count / total_time_s if total_time_s > 0 else 0\n",
        "\n",
        "    # POR (Point of Regard) velocity\n",
        "    por_x_diff = df['por_binocular_x'].diff()\n",
        "    por_y_diff = df['por_binocular_y'].diff()\n",
        "\n",
        "    por_velocity = np.sqrt(por_x_diff**2 + por_y_diff**2) / time_diff_series\n",
        "    por_velocity = por_velocity.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "    por_velocity_mean = por_velocity.mean() if not por_velocity.empty else 0\n",
        "    por_velocity_std = por_velocity.std() if not por_velocity.empty else 0\n",
        "\n",
        "    return {\n",
        "        'blink_rate': blink_rate,\n",
        "        'avg_blink_duration': avg_blink_duration,\n",
        "        'fixation_percentage': fixation_percentage,\n",
        "        'saccade_mean': saccade_mean,\n",
        "        'saccade_max': saccade_max,\n",
        "        'saccade_frequency': saccade_frequency,\n",
        "        'por_velocity_mean': por_velocity_mean,\n",
        "        'por_velocity_std': por_velocity_std\n",
        "    }\n",
        "'''"
      ],
      "metadata": {
        "id": "J208qmAabNwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import pandas as pd\n",
        "import os\n",
        "\n",
        "# Assuming your extract_features function is ready\n",
        "\n",
        "folder_path = 'new_folder'\n",
        "all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for file in all_files:\n",
        "    features = extract_features(file)\n",
        "    data.append(features)\n",
        "\n",
        "    if os.path.basename(file).startswith('P_'):\n",
        "        labels.append(1)  # Patient\n",
        "    else:\n",
        "        labels.append(0)  # Non-patient\n",
        "\n",
        "# Create final dataset\n",
        "feature_df = pd.DataFrame(data)\n",
        "feature_df['label'] = labels\n",
        "\n",
        "print(\"Dataset preview:\")\n",
        "print(feature_df.head())\n",
        "print(f\"Total samples: {len(feature_df)}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym9iJKgca6_1",
        "outputId": "30813e08-9e2c-47ab-88a2-09e5479f9f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n",
            "<ipython-input-6-4195348161>:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  time_diff_series = time_diff_series.replace(0, np.nan).fillna(method='bfill')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset preview:\n",
            "   blink_rate  avg_blink_duration  fixation_percentage  saccade_mean  \\\n",
            "0    1.814881            0.051240             0.050900      0.477543   \n",
            "1  404.268887            0.000004             0.001576    133.214295   \n",
            "2  456.430625            0.000553             0.053601    147.147547   \n",
            "3    0.567997            0.032902             0.076700      0.519501   \n",
            "4    1.491164            0.041827             0.025500      0.166146   \n",
            "\n",
            "    saccade_max  saccade_frequency  por_velocity_mean  por_velocity_std  label  \n",
            "0     24.837986           0.000000        1344.243839      11064.820758      1  \n",
            "1   2829.905201      147933.536270      825573.992902     603382.572876      0  \n",
            "2  15092.420380      128818.766330      600359.325224     664740.769795      0  \n",
            "3     34.077435           0.006406         953.024440       2092.690415      1  \n",
            "4     38.099731           0.002018        1797.759761       3941.515127      1  \n",
            "Total samples: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate features and labels\n",
        "X = feature_df.drop('label', axis=1)\n",
        "y = feature_df['label']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)'''\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mf0nSAgBc5rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "folder_path = 'new_folder'\n",
        "all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for file in all_files:\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    # Add label to each row based on file name\n",
        "    if os.path.basename(file).startswith('P_'):\n",
        "        df['label'] = 1  # Patient\n",
        "    else:\n",
        "        df['label'] = 0  # Non-patient\n",
        "\n",
        "    all_data.append(df)\n",
        "\n",
        "# Combine all rows from all files\n",
        "final_df = pd.concat(all_data, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "Ty3QQYqeqBw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features for training\n",
        "features = ['blink', 'saccade_velocity', 'fixation', 'pupil_size']  # You can add more\n",
        "\n",
        "X = final_df[features]\n",
        "y = final_df['label']\n"
      ],
      "metadata": {
        "id": "woqBxt_FqGGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sequence_length = 50  # You can try 30, 50, 100\n",
        "\n",
        "def create_sequences(X, y, sequence_length):\n",
        "    X_seq = []\n",
        "    y_seq = []\n",
        "\n",
        "    for i in range(len(X) - sequence_length):\n",
        "        X_seq.append(X.iloc[i:i+sequence_length].values)\n",
        "        y_seq.append(y.iloc[i+sequence_length - 1])  # Label of the last row in the sequence\n",
        "\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "X_sequences, y_sequences = create_sequences(X, y, sequence_length)\n",
        "\n",
        "print(f\"X shape: {X_sequences.shape}, y shape: {y_sequences.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAiN8gq2qPuo",
        "outputId": "557ebdc7-fa1f-4c89-8c7e-fc53deda8f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (86906, 50, 4), y shape: (86906,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.3, random_state=42, stratify=y_sequences)\n"
      ],
      "metadata": {
        "id": "0wcbgqy8ruAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(sequence_length, len(features)), return_sequences=False),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "91fF6eYqrxhZ",
        "outputId": "23421372-1c55-4214-ad22-73afa12e6e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m17,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,777\u001b[0m (77.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,777</span> (77.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,777\u001b[0m (77.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,777</span> (77.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWZlz0INr3Rq",
        "outputId": "5860acc4-376b-4695-b7f0-f893fe677e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5436 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.5404 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5413 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.5401 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.5432 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.5416 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.5356 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.5409 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.5424 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5413 - loss: nan - val_accuracy: 0.5403 - val_loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_classes))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYL2o4ebsnJk",
        "outputId": "eae0477a-0546-4a01-a75c-cd4128e850b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5447 - loss: nan\n",
            "Test Accuracy: 0.5403\n",
            "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "Confusion Matrix:\n",
            "[[14087     0]\n",
            " [11985     0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      1.00      0.70     14087\n",
            "           1       0.00      0.00      0.00     11985\n",
            "\n",
            "    accuracy                           0.54     26072\n",
            "   macro avg       0.27      0.50      0.35     26072\n",
            "weighted avg       0.29      0.54      0.38     26072\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Build the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Cross-validation (harder test)\n",
        "scores = cross_val_score(model, X_train_scaled, y_train, cv=3)\n",
        "\n",
        "print(f\"Cross-validation accuracy scores: {scores}\")\n",
        "print(f\"Mean cross-validation accuracy: {scores.mean():.4f}\")'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xnjb6o2oZQH",
        "outputId": "37d6a5e2-ff63-4550-d251-39fd29323121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation accuracy scores: [1. 1. 1.]\n",
            "Mean cross-validation accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}